#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºæ™ºè°±GLMçš„ç½‘ç»œå®‰å…¨æ–°é—»ç”Ÿæˆå™¨
å‚è€ƒï¼šhttps://docs.bigmodel.cn/cn/best-practice/creativepractice/aimorningnewspaper
"""

import requests
import json
from datetime import datetime, timedelta
import logging
import os
from typing import List, Dict
import feedparser
from bs4 import BeautifulSoup
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('glm_news.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class GLMNewsGenerator:
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–GLMæ–°é—»ç”Ÿæˆå™¨
        
        Args:
            api_key: æ™ºè°±GLM APIå¯†é’¥
        """
        self.api_key = api_key or os.getenv('GLM_API_KEY')
        self.base_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # åŠ è½½æ–°é—»æºé…ç½®
        try:
            from src.core.news_sources_loader import NewsSourcesLoader
            self.sources_loader = NewsSourcesLoader()
            self.news_sources = self.sources_loader.get_enabled_sources()
            logger.info(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½äº† {len(self.news_sources)} ä¸ªæ–°é—»æº")
        except ImportError:
            try:
                from news_sources_loader import NewsSourcesLoader
                self.sources_loader = NewsSourcesLoader()
                self.news_sources = self.sources_loader.get_enabled_sources()
                logger.info(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½äº† {len(self.news_sources)} ä¸ªæ–°é—»æº")
            except ImportError:
                logger.warning("âš ï¸ æ–°é—»æºé…ç½®åŠ è½½å™¨æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                # å¤‡ç”¨é»˜è®¤é…ç½®
                self.news_sources = [
                    {
                        'name': 'å®‰å…¨å®¢',
                        'rss_url': 'https://api.anquanke.com/data/v1/rss',
                        'weight': 1.0,
                        'language': 'zh',
                        'region': 'ä¸­å›½',
                        'category': 'ç»¼åˆå®‰å…¨',
                        'enabled': True
                    },
                    {
                        'name': 'FreeBuf',
                        'rss_url': 'https://www.freebuf.com/feed',
                        'weight': 1.0,
                        'language': 'zh',
                        'region': 'ä¸­å›½',
                        'category': 'ç»¼åˆå®‰å…¨',
                        'enabled': True
                    },
                    {
                        'name': 'å˜¶å¼',
                        'rss_url': 'https://www.4hou.com/feed',
                        'weight': 1.0,
                        'language': 'zh',
                        'region': 'ä¸­å›½',
                        'category': 'ç»¼åˆå®‰å…¨',
                        'enabled': True
                    }
                ]
            # å¤‡ç”¨é»˜è®¤é…ç½®
            self.news_sources = [
                {
                    'name': 'å®‰å…¨å®¢',
                    'rss_url': 'https://api.anquanke.com/data/v1/rss',
                    'weight': 1.0,
                    'language': 'zh',
                    'region': 'ä¸­å›½',
                    'category': 'ç»¼åˆå®‰å…¨',
                    'enabled': True
                },
                {
                    'name': 'FreeBuf',
                    'rss_url': 'https://www.freebuf.com/feed',
                    'weight': 1.0,
                    'language': 'zh',
                    'region': 'ä¸­å›½',
                    'category': 'ç»¼åˆå®‰å…¨',
                    'enabled': True
                },
                {
                    'name': 'å˜¶å¼',
                    'rss_url': 'https://www.4hou.com/feed',
                    'weight': 1.0,
                    'language': 'zh',
                    'region': 'ä¸­å›½',
                    'category': 'ç»¼åˆå®‰å…¨',
                    'enabled': True
                }
            ]
        
        self.security_keywords = [
            'å®‰å…¨', 'æ¼æ´', 'æ”»å‡»', 'é»‘å®¢', 'ç—…æ¯’', 'æ¶æ„è½¯ä»¶', 'å‹’ç´¢', 'æ¸—é€',
            'é˜²æŠ¤', 'é˜²å¾¡', 'åŠ å¯†', 'è§£å¯†', 'éšç§', 'æ•°æ®æ³„éœ²', 'ç½‘ç»œå®‰å…¨',
            'APT', 'DDoS', 'é’“é±¼', 'æœ¨é©¬', 'åé—¨', 'ææƒ', 'CVE', 'RCE'
        ]
    
    def call_glm_api(self, prompt: str, model: str = "glm-4-flash") -> str:
        """
        è°ƒç”¨æ™ºè°±GLM API
        
        Args:
            prompt: è¾“å…¥æç¤ºè¯
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
        """
        try:
            payload = {
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.7,
                "max_tokens": 2000
            }
            
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                logger.error(f"GLM APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return ""
                
        except Exception as e:
            logger.error(f"GLM APIè°ƒç”¨å¼‚å¸¸: {e}")
            return ""
    
    def fetch_article_content(self, url: str, max_length: int = 3000) -> Dict:
        """
        ä½¿ç”¨å¢å¼ºå‹çˆ¬è™«æŠ“å–æ–‡ç« å®Œæ•´å†…å®¹
        
        Args:
            url: æ–‡ç« é“¾æ¥
            max_length: æœ€å¤§å†…å®¹é•¿åº¦
            
        Returns:
            åŒ…å«å®Œæ•´æ–‡ç« ä¿¡æ¯çš„å­—å…¸
        """
        try:
            from src.crawlers.enhanced_crawler import EnhancedNewsCrawler
            crawler = EnhancedNewsCrawler()
            result = crawler.extract_article_content(url, max_length)
            
            if result['success']:
                logger.info(f"æˆåŠŸæå–æ–‡ç« å†…å®¹: {result['title'][:50]}... ({result['char_count']}å­—ç¬¦)")
                return result
            else:
                logger.warning(f"å¢å¼ºçˆ¬è™«æå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {url}")
                return self._fallback_content_extraction(url, max_length)
                
        except ImportError:
            try:
                from enhanced_crawler import EnhancedNewsCrawler
                crawler = EnhancedNewsCrawler()
                result = crawler.extract_article_content(url, max_length)
                
                if result['success']:
                    logger.info(f"æˆåŠŸæå–æ–‡ç« å†…å®¹: {result['title'][:50]}... ({result['char_count']}å­—ç¬¦)")
                    return result
                else:
                    logger.warning(f"å¢å¼ºçˆ¬è™«æå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {url}")
                    return self._fallback_content_extraction(url, max_length)
                    
            except ImportError:
                logger.warning("å¢å¼ºçˆ¬è™«æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                return self._fallback_content_extraction(url, max_length)
        except Exception as e:
            logger.warning(f"å¢å¼ºçˆ¬è™«æå–å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self._fallback_content_extraction(url, max_length)
            return self._fallback_content_extraction(url, max_length)
        except Exception as e:
            logger.warning(f"å¢å¼ºçˆ¬è™«æå–å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self._fallback_content_extraction(url, max_length)
    
    def _fallback_content_extraction(self, url: str, max_length: int = 3000) -> Dict:
        """
        å¤‡ç”¨å†…å®¹æå–æ–¹æ³•
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'advertisement']):
                tag.decompose()
            
            # å°è¯•æ‰¾åˆ°ä¸»è¦å†…å®¹åŒºåŸŸ
            content_selectors = [
                'article', '.article-content', '.post-content', '.entry-content',
                '.content', '.main-content', '.article-body', '.post-body',
                '[role="main"]', '.story-body', '.article-text'
            ]
            
            content = ""
            for selector in content_selectors:
                elements = soup.select(selector)
                if elements:
                    content = elements[0].get_text(strip=True)
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šçš„å†…å®¹åŒºåŸŸï¼Œä½¿ç”¨æ•´ä¸ªbody
            if not content:
                body = soup.find('body')
                if body:
                    content = body.get_text(strip=True)
            
            # æ¸…ç†å’Œæˆªæ–­å†…å®¹
            if content:
                # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
                content = ' '.join(content.split())
                # æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦
                if len(content) > max_length:
                    content = content[:max_length] + "..."
            
            # æå–æ ‡é¢˜
            title = ""
            title_tag = soup.find('title')
            if title_tag:
                title = title_tag.get_text(strip=True)
            
            return {
                'title': title,
                'content': content,
                'summary': content[:200] + "..." if len(content) > 200 else content,
                'char_count': len(content),
                'word_count': len(content.split()),
                'success': True,
                'url': url
            }
            
        except Exception as e:
            logger.warning(f"å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥ {url}: {e}")
            return {
                'title': '',
                'content': '',
                'summary': '',
                'char_count': 0,
                'word_count': 0,
                'success': False,
                'url': url,
                'error': str(e)
            }
    
    def fetch_security_news(self, days_back: int = 1) -> List[Dict]:
        """
        æŠ“å–ç½‘ç»œå®‰å…¨æ–°é—»
        
        Args:
            days_back: æŠ“å–å‡ å¤©å‰çš„æ–°é—»
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        target_date = (datetime.now() - timedelta(days=days_back)).date()
        all_news = []
        
        logger.info(f"å¼€å§‹æŠ“å– {target_date} çš„ç½‘ç»œå®‰å…¨æ–°é—»...")
        
        for source in self.news_sources:
            if not source.get('enabled', True):
                continue
                
            try:
                logger.info(f"æ­£åœ¨æŠ“å– {source['name']} ({source.get('region', 'Unknown')}) çš„RSSæº...")
                
                # è®¾ç½®è¯·æ±‚å¤´
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                
                # è·å–RSSå†…å®¹
                response = requests.get(source['rss_url'], headers=headers, timeout=15)
                feed = feedparser.parse(response.content)
                source_news = []
                
                for entry in feed.entries:
                    # è§£æå‘å¸ƒæ—¶é—´
                    pub_date = None
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        pub_date = datetime(*entry.published_parsed[:6]).date()
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        pub_date = datetime(*entry.updated_parsed[:6]).date()
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡æ—¥æœŸçš„æ–°é—»ï¼ˆå…è®¸3å¤©å†…çš„æ–°é—»ï¼‰
                    if pub_date and (datetime.now().date() - pub_date).days <= 3:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºå®‰å…¨ç›¸å…³æ–°é—»
                        title = entry.title.lower()
                        summary = getattr(entry, 'summary', '').lower()
                        
                        # æ‰©å±•å…³é”®è¯åŒ¹é…é€»è¾‘
                        is_security_related = any(keyword.lower() in title or keyword.lower() in summary 
                                                for keyword in self.security_keywords)
                        
                        if is_security_related:
                            # è·å–æ–‡ç« å®Œæ•´å†…å®¹
                            article_data = {'content': '', 'title': entry.title, 'summary': ''}
                            
                            if hasattr(entry, 'content') and entry.content:
                                # RSSä¸­åŒ…å«å†…å®¹
                                rss_content = entry.content[0].value if isinstance(entry.content, list) else str(entry.content)
                                # æ¸…ç†HTMLæ ‡ç­¾
                                soup = BeautifulSoup(rss_content, 'html.parser')
                                article_data['content'] = soup.get_text(strip=True)
                                article_data['summary'] = article_data['content'][:200] + "..." if len(article_data['content']) > 200 else article_data['content']
                            elif entry.link:
                                # ä½¿ç”¨å¢å¼ºå‹çˆ¬è™«æŠ“å–å®Œæ•´æ–‡ç« å†…å®¹
                                logger.info(f"æ­£åœ¨ä½¿ç”¨å¢å¼ºçˆ¬è™«æŠ“å–: {entry.title[:50]}...")
                                article_data = self.fetch_article_content(entry.link)
                                
                                # å¦‚æœå¢å¼ºçˆ¬è™«è·å–çš„æ ‡é¢˜æ›´å¥½ï¼Œä½¿ç”¨å®ƒ
                                if article_data.get('title') and len(article_data['title']) > len(entry.title):
                                    entry.title = article_data['title']
                            
                            # ä½¿ç”¨RSSæ‘˜è¦ä½œä¸ºå¤‡é€‰
                            if not article_data.get('summary'):
                                article_data['summary'] = getattr(entry, 'summary', '')
                            
                            news_item = {
                                'title': entry.title,
                                'link': entry.link,
                                'summary': article_data.get('summary', ''),
                                'content': article_data.get('content', ''),
                                'enhanced_content': article_data.get('success', False),  # æ ‡è®°æ˜¯å¦ä½¿ç”¨äº†å¢å¼ºæŠ“å–
                                'char_count': article_data.get('char_count', 0),
                                'word_count': article_data.get('word_count', 0),
                                'metadata': article_data.get('metadata', {}),
                                'published_date': pub_date,
                                'source': source['name'],
                                'weight': source['weight'],
                                'language': source.get('language', 'en'),
                                'region': source.get('region', 'Unknown')
                            }
                            source_news.append(news_item)
                
                logger.info(f"ä» {source['name']} è·å–åˆ° {len(source_news)} æ¡å®‰å…¨æ–°é—»")
                all_news.extend(source_news)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(2)
                
            except Exception as e:
                logger.error(f"æŠ“å– {source['name']} å¤±è´¥: {e}")
                continue
        
        # å»é‡å’Œæ’åº
        unique_news = []
        seen_titles = set()
        
        for news in all_news:
            # ä½¿ç”¨æ ‡é¢˜çš„å‰50ä¸ªå­—ç¬¦è¿›è¡Œå»é‡ï¼Œé¿å…å®Œå…¨ç›¸åŒçš„æ ‡é¢˜
            title_key = news['title'][:50].lower()
            if title_key not in seen_titles:
                unique_news.append(news)
                seen_titles.add(title_key)
        
        # æŒ‰æƒé‡å’Œæ—¶é—´æ’åºï¼Œå–å‰15æ¡ï¼ˆå¢åŠ æ•°é‡ä»¥è·å¾—æ›´å¥½çš„é€‰æ‹©ï¼‰
        unique_news.sort(key=lambda x: (x['weight'], x['published_date']), reverse=True)
        
        logger.info(f"æ€»å…±è·å–åˆ° {len(unique_news)} æ¡ä¸é‡å¤çš„å®‰å…¨æ–°é—»")
        return unique_news[:15]
    
    def select_top_news(self, news_list: List[Dict]) -> List[Dict]:
        """
        ä½¿ç”¨GLMä»æ‰€æœ‰æ–°é—»ä¸­ç²¾é€‰å‡ºæœ€é‡è¦çš„10ç¯‡
        
        Args:
            news_list: å…¨éƒ¨æ–°é—»åˆ—è¡¨
            
        Returns:
            ç²¾é€‰çš„10ç¯‡æ–°é—»
        """
        if len(news_list) <= 10:
            return news_list
        
        # æ„å»ºæ–°é—»ä¿¡æ¯ç”¨äºGLMåˆ†æ
        news_details = []
        for i, news in enumerate(news_list):
            content_preview = ""
            if news.get('content'):
                content_preview = news['content'][:200] + "..." if len(news['content']) > 200 else news['content']
            elif news.get('summary'):
                content_preview = news['summary'][:200] + "..." if len(news['summary']) > 200 else news['summary']
            
            news_detail = f"{i+1}. ã€{news['source']} - {news.get('region', 'Unknown')}ã€‘{news['title']}\n"
            if content_preview:
                news_detail += f"   å†…å®¹: {content_preview}\n"
            news_details.append(news_detail)
        
        news_text = "\n".join(news_details)
        
        # ä½¿ç”¨GLMç²¾é€‰æ–°é—»
        try:
            from config.glm_config import PROMPT_TEMPLATES
        except ImportError:
            # å¤‡ç”¨å¯¼å…¥è·¯å¾„
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
            from config.glm_config import PROMPT_TEMPLATES
        select_prompt = PROMPT_TEMPLATES['select_top_news'].format(news_text=news_text)
        
        select_result = self.call_glm_api(select_prompt)
        
        # è§£æç²¾é€‰ç»“æœ
        selected_indices = []
        try:
            result_data = json.loads(select_result)
            selected_news = result_data.get('selected_news', [])
            
            # æ ¹æ®æ ‡é¢˜åŒ¹é…æ‰¾åˆ°å¯¹åº”çš„æ–°é—»ç´¢å¼•
            for selected in selected_news:
                selected_title = selected['title']
                for i, news in enumerate(news_list):
                    if selected_title in news['title'] or news['title'] in selected_title:
                        if i not in selected_indices:
                            selected_indices.append(i)
                        break
            
        except Exception as e:
            logger.warning(f"æ–°é—»ç²¾é€‰ç»“æœè§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é€‰æ‹©")
            # é»˜è®¤é€‰æ‹©ï¼šæŒ‰æƒé‡å’Œæ—¶é—´æ’åºå–å‰10æ¡
            sorted_news = sorted(enumerate(news_list), 
                               key=lambda x: (x[1].get('weight', 0), x[1].get('published_date', datetime.min.date())), 
                               reverse=True)
            selected_indices = [i for i, _ in sorted_news[:10]]
        
        # ç¡®ä¿é€‰æ‹©äº†10ç¯‡æ–°é—»
        if len(selected_indices) < 10:
            remaining_indices = [i for i in range(len(news_list)) if i not in selected_indices]
            selected_indices.extend(remaining_indices[:10-len(selected_indices)])
        
        selected_news = [news_list[i] for i in selected_indices[:10]]
        logger.info(f"æˆåŠŸç²¾é€‰å‡º {len(selected_news)} ç¯‡å…¨çƒå®‰å…¨æ–°é—»")
        
        return selected_news

    def generate_news_analysis(self, news_list: List[Dict]) -> Dict:
        """
        ä½¿ç”¨GLMç”Ÿæˆæ–°é—»åˆ†æå’Œæ‘˜è¦
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            åŒ…å«åˆ†æå†…å®¹çš„å­—å…¸
        """
        if not news_list:
            return {"summary": "ä»Šæ—¥æš‚æ— ç½‘ç»œå®‰å…¨æ–°é—»", "categories": {}}
        
        # é¦–å…ˆç²¾é€‰10ç¯‡æœ€é‡è¦çš„æ–°é—»
        logger.info("æ­£åœ¨ä½¿ç”¨GLMç²¾é€‰å…¨çƒé‡è¦å®‰å…¨æ–°é—»...")
        selected_news = self.select_top_news(news_list)
        
        # æ„å»ºç²¾é€‰æ–°é—»çš„è¯¦ç»†ä¿¡æ¯ - åˆ©ç”¨å¢å¼ºçˆ¬è™«è·å–çš„ä¸°å¯Œå†…å®¹
        news_details = []
        for i, news in enumerate(selected_news):
            content_preview = ""
            
            # ä¼˜å…ˆä½¿ç”¨å¢å¼ºçˆ¬è™«è·å–çš„å®Œæ•´å†…å®¹
            if news.get('enhanced_content') and news.get('content'):
                content_preview = news['content'][:500] + "..." if len(news['content']) > 500 else news['content']
                content_quality = "å¢å¼ºå†…å®¹"
            elif news.get('summary'):
                content_preview = news['summary']
                content_quality = "RSSæ‘˜è¦"
            else:
                content_preview = "å†…å®¹è·å–å¤±è´¥"
                content_quality = "æ— å†…å®¹"
            
            news_detail = f"{i+1}. ã€{news['source']} - {news.get('region', 'Unknown')}ã€‘{news['title']}\n"
            news_detail += f"   å†…å®¹è´¨é‡: {content_quality} ({news.get('char_count', 0)}å­—ç¬¦)\n"
            if content_preview:
                news_detail += f"   è¯¦ç»†å†…å®¹: {content_preview}\n"
            news_detail += f"   è¯­è¨€: {news.get('language', 'unknown')}\n"
            
            # å¦‚æœæœ‰å…ƒæ•°æ®ï¼Œä¹ŸåŒ…å«è¿›æ¥
            if news.get('metadata'):
                metadata = news['metadata']
                if metadata.get('author'):
                    news_detail += f"   ä½œè€…: {metadata['author']}\n"
                if metadata.get('publish_time'):
                    news_detail += f"   å‘å¸ƒæ—¶é—´: {metadata['publish_time']}\n"
            
            news_details.append(news_detail)
        
        news_text = "\n".join(news_details)
        
        # ç”Ÿæˆå…¨çƒå®‰å…¨æ€åŠ¿æ‘˜è¦
        try:
            from config.glm_config import PROMPT_TEMPLATES
        except ImportError:
            # å¤‡ç”¨å¯¼å…¥è·¯å¾„
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
            from config.glm_config import PROMPT_TEMPLATES
        summary_prompt = PROMPT_TEMPLATES['summary'].format(news_text=news_text)
        summary = self.call_glm_api(summary_prompt)
        
        # æŒ‰å››ä¸ªç»´åº¦åˆ†ç±»å¹¶ç”Ÿæˆå®Œæ•´è¦ç´ æ€»ç»“
        category_prompt = PROMPT_TEMPLATES['categorize_and_summarize'].format(news_text=news_text)
        category_result = self.call_glm_api(category_prompt)
        
        # è§£æåˆ†ç±»ç»“æœ
        categories = {}
        try:
            categories = json.loads(category_result)
            logger.info("æˆåŠŸä½¿ç”¨GLMè¿›è¡Œå››ç»´åº¦æ–°é—»åˆ†ç±»å’Œè¦ç´ æ€»ç»“")
        except Exception as e:
            logger.warning(f"åˆ†ç±»ç»“æœè§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»")
            categories = self._default_categorize_news_four_dimensions(selected_news)
        
        # ç»Ÿè®¡å¢å¼ºå†…å®¹çš„æ•ˆæœ
        enhanced_count = sum(1 for news in selected_news if news.get('enhanced_content', False))
        total_chars = sum(news.get('char_count', 0) for news in selected_news)
        
        return {
            "summary": summary,
            "categories": categories,
            "total_news": len(selected_news),
            "original_count": len(news_list),
            "enhanced_count": enhanced_count,
            "total_chars": total_chars,
            "sources": list(set([news['source'] for news in selected_news])),
            "regions": list(set([news.get('region', 'Unknown') for news in selected_news])),
            "languages": list(set([news.get('language', 'unknown') for news in selected_news]))
        }
    
    def _default_categorize_news_four_dimensions(self, news_list: List[Dict]) -> Dict:
        """
        é»˜è®¤å››ç»´åº¦æ–°é—»åˆ†ç±»é€»è¾‘ï¼ˆå½“AIåˆ†ç±»å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        """
        categories = {
            "å®‰å…¨é£é™©": [],
            "å®‰å…¨äº‹ä»¶": [],
            "å®‰å…¨èˆ†æƒ…": [],
            "å®‰å…¨è¶‹åŠ¿": []
        }
        
        # åŸºäºå…³é”®è¯çš„å››ç»´åº¦åˆ†ç±»
        for news in news_list:
            title_lower = news['title'].lower()
            content_lower = (news.get('content', '') + news.get('summary', '')).lower()
            
            # ç”ŸæˆåŒ…å«å…³é”®è¦ç´ çš„æ€»ç»“
            summary_text = ""
            if news.get('content'):
                summary_text = news['content'][:150] + "..."
            elif news.get('summary'):
                summary_text = news['summary'][:150] + "..."
            else:
                summary_text = f"æ¥è‡ª{news['source']}çš„å®‰å…¨æ–°é—»ï¼Œè¯¦ç»†å†…å®¹è¯·æŸ¥çœ‹åŸæ–‡ã€‚"
            
            # ç¿»è¯‘è‹±æ–‡æ ‡é¢˜ï¼ˆç®€å•å¤„ç†ï¼‰
            display_title = news['title']
            if news.get('language') == 'en':
                display_title = f"[å›½é™…] {news['title']}"
            
            item = {
                "title": display_title,
                "source": news['source'],
                "region": news.get('region', 'Unknown'),
                "summary": summary_text,
                "key_points": [
                    f"æ¥æºï¼š{news['source']}",
                    f"åœ°åŒºï¼š{news.get('region', 'Unknown')}",
                    "è¯¦ç»†åˆ†æè¯·æŸ¥çœ‹åŸæ–‡"
                ],
                "impact_level": "ä¸­"
            }
            
            # å››ç»´åº¦å…³é”®è¯åˆ†ç±»
            if any(keyword in title_lower or keyword in content_lower for keyword in 
                   ['vulnerability', 'cve', 'exploit', 'æ¼æ´', 'å¨èƒ', 'threat', 'risk', 'é£é™©']):
                categories["å®‰å…¨é£é™©"].append(item)
            elif any(keyword in title_lower or keyword in content_lower for keyword in 
                     ['breach', 'attack', 'hack', 'æ”»å‡»', 'æ³„éœ²', 'å…¥ä¾µ', 'å‹’ç´¢', 'incident']):
                categories["å®‰å…¨äº‹ä»¶"].append(item)
            elif any(keyword in title_lower or keyword in content_lower for keyword in 
                     ['policy', 'regulation', 'compliance', 'æ”¿ç­–', 'æ³•è§„', 'åˆè§„', 'æŠ¥å‘Š', 'report']):
                categories["å®‰å…¨èˆ†æƒ…"].append(item)
            else:
                categories["å®‰å…¨è¶‹åŠ¿"].append(item)
        
        return categories
    
    def translate_english_news(self, news: Dict) -> Dict:
        """
        ç¿»è¯‘è‹±æ–‡æ–°é—»ä¸ºä¸­æ–‡å¹¶è¿›è¡Œåˆ†æ
        
        Args:
            news: è‹±æ–‡æ–°é—»å­—å…¸
            
        Returns:
            ç¿»è¯‘å’Œåˆ†æåçš„æ–°é—»å­—å…¸
        """
        if news.get('language') != 'en' or not news.get('content'):
            return news
        
        try:
            from config.glm_config import PROMPT_TEMPLATES
        except ImportError:
            # å¤‡ç”¨å¯¼å…¥è·¯å¾„
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
            from config.glm_config import PROMPT_TEMPLATES
            translate_prompt = PROMPT_TEMPLATES['translate_and_analyze'].format(
                title=news['title'],
                content=news.get('content', '')[:1000],  # é™åˆ¶é•¿åº¦é¿å…è¶…æ—¶
                source=news['source']
            )
            
            translate_result = self.call_glm_api(translate_prompt)
            result_data = json.loads(translate_result)
            
            # æ›´æ–°æ–°é—»ä¿¡æ¯
            news['chinese_title'] = result_data.get('chinese_title', news['title'])
            news['translated_summary'] = result_data.get('summary', '')
            news['key_points'] = result_data.get('key_points', [])
            news['impact_analysis'] = result_data.get('impact_analysis', '')
            news['threat_level'] = result_data.get('threat_level', 'ä¸­å±')
            
            logger.info(f"æˆåŠŸç¿»è¯‘è‹±æ–‡æ–°é—»: {news['title'][:50]}...")
            
        except Exception as e:
            logger.warning(f"ç¿»è¯‘è‹±æ–‡æ–°é—»å¤±è´¥: {e}")
        
        return news
    
    def generate_html_report(self, analysis_result: Dict, date_str: str) -> str:
        """
        ç”ŸæˆHTMLæ ¼å¼çš„æ–°é—»å¿«æŠ¥
        
        Args:
            analysis_result: åˆ†æç»“æœ
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            
        Returns:
            HTMLå†…å®¹
        """
        current_time = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        # å¯¼å…¥æ ·å¼ä¿æŠ¤æ¨¡å—
        try:
            from style_protection import get_mobile_responsive_css, ensure_mobile_responsive
            mobile_css = get_mobile_responsive_css()
            logger.info("âœ… æˆåŠŸåŠ è½½ç§»åŠ¨ç«¯æ ·å¼ä¿æŠ¤æ¨¡å—")
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨å†…ç½®çš„ç§»åŠ¨ç«¯æ ·å¼
            mobile_css = self._get_fallback_mobile_css()
            logger.warning("âš ï¸ æ ·å¼ä¿æŠ¤æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å†…ç½®å¤‡ç”¨æ ·å¼")
        
        html_template = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>æµ·ä¹‹å®‰ç½‘ç»œå®‰å…¨æ—¥æŠ¥ - {current_time}</title>
  
  <style>
    * {{
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }}
    
    body {{
      font-family: 'Microsoft YaHei', 'SimHei', 'Arial', sans-serif;
      background: linear-gradient(135deg, #0f172a 0%, #1e293b 50%, #334155 100%);
      color: #f1f5f9;
      min-height: 100vh;
      padding: 20px;
      line-height: 1.6;
    }}
    
    .container {{
      max-width: 1200px;
      margin: 0 auto;
      background: rgba(15, 23, 42, 0.95);
      border: 1px solid rgba(59, 130, 246, 0.3);
      border-radius: 16px;
      box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.8);
      overflow: hidden;
    }}
    
    .header {{
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.1) 0%, rgba(147, 51, 234, 0.1) 100%);
      border-bottom: 1px solid rgba(59, 130, 246, 0.3);
      padding: 40px;
      text-align: center;
      position: relative;
    }}
    
    .header::before {{
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 2px;
      background: linear-gradient(90deg, #3b82f6, #8b5cf6, #06b6d4);
    }}
    
    .logo {{
      width: 200px;
      height: auto;
      margin-bottom: 20px;
    }}
    
    .title {{
      font-size: 36px;
      font-weight: 700;
      background: linear-gradient(135deg, #3b82f6, #8b5cf6);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      margin-bottom: 16px;
    }}
    
    .subtitle {{
      font-size: 18px;
      color: #94a3b8;
      margin-bottom: 8px;
    }}
    
    .content {{
      padding: 40px;
    }}
    
    .summary-section {{
      background: rgba(30, 41, 59, 0.8);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 12px;
      padding: 24px;
      margin-bottom: 32px;
    }}
    
    .summary-title {{
      font-size: 20px;
      font-weight: 600;
      color: #3b82f6;
      margin-bottom: 16px;
      display: flex;
      align-items: center;
      gap: 8px;
    }}
    
    .summary-title::before {{
      content: 'ğŸ“Š';
      font-size: 24px;
    }}
    
    .summary-content {{
      color: #cbd5e1;
      line-height: 1.8;
      font-size: 16px;
    }}
    
    .category-section {{
      margin-bottom: 40px;
      background: rgba(30, 41, 59, 0.4);
      border-radius: 12px;
      border: 1px solid rgba(59, 130, 246, 0.15);
      overflow: hidden;
    }}
    
    .category-header {{
      background: linear-gradient(135deg, rgba(59, 130, 246, 0.2), rgba(147, 51, 234, 0.2));
      padding: 20px 24px;
      border-bottom: 1px solid rgba(59, 130, 246, 0.3);
    }}
    
    .category-title {{
      font-size: 24px;
      font-weight: 600;
      color: #e2e8f0;
      display: flex;
      align-items: center;
      gap: 12px;
    }}
    
    .category-news {{
      padding: 24px;
    }}
    
    .news-item {{
      background: rgba(51, 65, 85, 0.6);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      transition: all 0.3s ease;
      position: relative;
    }}
    
    .news-item::before {{
      content: '';
      position: absolute;
      left: 0;
      top: 0;
      bottom: 0;
      width: 4px;
      background: linear-gradient(180deg, #3b82f6, #8b5cf6);
      border-radius: 2px 0 0 2px;
    }}
    
    .news-item:hover {{
      border-color: rgba(59, 130, 246, 0.4);
      box-shadow: 0 4px 12px rgba(59, 130, 246, 0.15);
    }}
    
    .news-title {{
      font-size: 18px;
      font-weight: 600;
      color: #f1f5f9;
      margin-bottom: 12px;
      line-height: 1.4;
    }}
    
    .news-analysis {{
      color: #cbd5e1;
      line-height: 1.7;
      font-size: 15px;
    }}
    
    .footer {{
      background: rgba(15, 23, 42, 0.8);
      border-top: 1px solid rgba(59, 130, 246, 0.3);
      padding: 24px 40px;
      text-align: center;
      color: #64748b;
      font-size: 14px;
    }}
    
    .stats-section {{
      margin-bottom: 32px;
    }}
    
    .stats-grid {{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 20px;
      margin-bottom: 20px;
    }}
    
    .stat-card {{
      background: rgba(30, 41, 59, 0.8);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 12px;
      padding: 20px;
      text-align: center;
      transition: all 0.3s ease;
    }}
    
    .stat-card:hover {{
      border-color: rgba(59, 130, 246, 0.4);
      transform: translateY(-2px);
    }}
    
    .stat-number {{
      font-size: 32px;
      font-weight: 700;
      color: #3b82f6;
      margin-bottom: 8px;
    }}
    
    .stat-label {{
      font-size: 14px;
      color: #94a3b8;
      margin-bottom: 4px;
    }}
    
    .stat-detail {{
      font-size: 12px;
      color: #64748b;
    }}
    
    .source-list {{
      margin-top: 24px;
      padding: 20px;
      background: rgba(30, 41, 59, 0.8);
      border-radius: 12px;
      border: 1px solid rgba(59, 130, 246, 0.2);
    }}
    
    .source-list h3 {{
      color: #3b82f6;
      font-size: 16px;
      margin-bottom: 12px;
    }}
    
    .source-tags {{
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
    }}
    
    .source-tag {{
      background: rgba(59, 130, 246, 0.1);
      color: #93c5fd;
      padding: 6px 12px;
      border-radius: 16px;
      font-size: 12px;
      border: 1px solid rgba(59, 130, 246, 0.2);
    }}
    
    .enhancement-info {{
      margin-top: 24px;
      padding: 20px;
      background: rgba(34, 197, 94, 0.1);
      border-radius: 12px;
      border: 1px solid rgba(34, 197, 94, 0.2);
    }}
    
    .enhancement-info h3 {{
      color: #22c55e;
      font-size: 16px;
      margin-bottom: 12px;
    }}
    
    .enhancement-stats {{
      display: flex;
      flex-direction: column;
      gap: 8px;
    }}
    
    .enhancement-item {{
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 8px 0;
      border-bottom: 1px solid rgba(34, 197, 94, 0.1);
    }}
    
    .enhancement-item:last-child {{
      border-bottom: none;
    }}
    
    .enhancement-label {{
      color: #94a3b8;
      font-size: 14px;
    }}
    
    .enhancement-value {{
      color: #22c55e;
      font-weight: 600;
      font-size: 14px;
    }}
    
    .content-quality-badge {{
      display: inline-block;
      padding: 4px 8px;
      border-radius: 4px;
      font-size: 11px;
      font-weight: 600;
      margin-left: 8px;
    }}
    
    .quality-enhanced {{
      background: rgba(34, 197, 94, 0.2);
      color: #86efac;
      border: 1px solid rgba(34, 197, 94, 0.3);
    }}
    
    .quality-rss {{
      background: rgba(245, 158, 11, 0.2);
      color: #fbbf24;
      border: 1px solid rgba(245, 158, 11, 0.3);
    }}
    
    .quality-failed {{
      background: rgba(239, 68, 68, 0.2);
      color: #fca5a5;
      border: 1px solid rgba(239, 68, 68, 0.3);
    }}
    
    .news-header {{
      margin-bottom: 12px;
    }}
    
    .news-meta {{
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-top: 8px;
      font-size: 12px;
    }}
    
    .news-source {{
      color: #94a3b8;
      background: rgba(59, 130, 246, 0.1);
      padding: 4px 8px;
      border-radius: 4px;
    }}
    
    .severity-badge {{
      padding: 4px 8px;
      border-radius: 4px;
      font-weight: 600;
      font-size: 11px;
    }}
    
    .severity-high {{
      background: rgba(239, 68, 68, 0.2);
      color: #fca5a5;
      border: 1px solid rgba(239, 68, 68, 0.3);
    }}
    
    .severity-medium {{
      background: rgba(245, 158, 11, 0.2);
      color: #fbbf24;
      border: 1px solid rgba(245, 158, 11, 0.3);
    }}
    
    .severity-low {{
      background: rgba(34, 197, 94, 0.2);
      color: #86efac;
      border: 1px solid rgba(34, 197, 94, 0.3);
    }}
    
    .severity-info {{
      background: rgba(59, 130, 246, 0.2);
      color: #93c5fd;
      border: 1px solid rgba(59, 130, 246, 0.3);
    }}
    
    .news-summary {{
      color: #cbd5e1;
      line-height: 1.7;
      font-size: 15px;
      margin-bottom: 12px;
    }}
    
    .key-points {{
      margin: 12px 0;
      padding-left: 20px;
      color: #94a3b8;
      font-size: 14px;
    }}
    
    .key-points li {{
      margin-bottom: 4px;
      line-height: 1.4;
    }}
    
    .region-badge {{
      background: rgba(34, 197, 94, 0.1);
      color: #86efac;
      padding: 4px 8px;
      border-radius: 4px;
      font-size: 11px;
      margin: 0 4px;
    }}
    
    .impact-badge {{
      padding: 4px 8px;
      border-radius: 4px;
      font-weight: 600;
      font-size: 11px;
    }}
    
    .impact-high {{
      background: rgba(239, 68, 68, 0.2);
      color: #fca5a5;
      border: 1px solid rgba(239, 68, 68, 0.3);
    }}
    
    .impact-medium {{
      background: rgba(245, 158, 11, 0.2);
      color: #fbbf24;
      border: 1px solid rgba(245, 158, 11, 0.3);
    }}
    
    .impact-low {{
      background: rgba(34, 197, 94, 0.2);
      color: #86efac;
      border: 1px solid rgba(34, 197, 94, 0.3);
    }}
    
    .icon-risk::before {{ content: 'âš ï¸'; }}
    .icon-event::before {{ content: 'ğŸš¨'; }}
    .icon-opinion::before {{ content: 'ğŸ“¢'; }}
    .icon-trend::before {{ content: 'ğŸ“ˆ'; }}
    .icon-focus::before {{ content: 'ğŸ¯'; }}
    
    /* ç§»åŠ¨ç«¯é€‚é…æ ·å¼ - é‡è¦ï¼šè¯·å‹¿åˆ é™¤æˆ–è¦†ç›– */
    @media (max-width: 768px) {{
      .container {{
        margin: 0;
        padding: 10px;
        border-radius: 0;
      }}
      
      .header {{
        padding: 20px 15px;
        border-radius: 0;
      }}
      
      .logo {{
        width: 150px;
        margin-bottom: 15px;
      }}
      
      .title {{
        font-size: 24px;
        margin-bottom: 12px;
      }}
      
      .subtitle {{
        font-size: 14px;
        margin-bottom: 6px;
      }}
      
      .content {{
        padding: 20px 15px;
      }}
      
      .summary-section {{
        padding: 15px;
        margin-bottom: 20px;
        border-radius: 8px;
      }}
      
      .summary-title {{
        font-size: 16px;
        margin-bottom: 12px;
      }}
      
      .summary-content {{
        font-size: 14px;
        line-height: 1.6;
      }}
      
      .stats-section {{
        margin-bottom: 20px;
      }}
      
      .stats-grid {{
        grid-template-columns: repeat(2, 1fr);
        gap: 10px;
      }}
      
      .stat-card {{
        padding: 15px;
        border-radius: 8px;
      }}
      
      .stat-number {{
        font-size: 24px;
        margin-bottom: 6px;
      }}
      
      .stat-label {{
        font-size: 12px;
      }}
      
      .stat-detail {{
        font-size: 10px;
      }}
      
      .enhancement-info {{
        padding: 15px;
        margin-top: 15px;
        border-radius: 8px;
      }}
      
      .enhancement-info h3 {{
        font-size: 14px;
        margin-bottom: 10px;
      }}
      
      .enhancement-item {{
        padding: 6px 0;
      }}
      
      .enhancement-label,
      .enhancement-value {{
        font-size: 12px;
      }}
      
      .source-list {{
        padding: 15px;
        margin-top: 15px;
        border-radius: 8px;
      }}
      
      .source-list h3 {{
        font-size: 14px;
        margin-bottom: 10px;
      }}
      
      .source-tag {{
        padding: 4px 8px;
        font-size: 10px;
        margin: 2px;
      }}
      
      .category-section {{
        margin-bottom: 25px;
        border-radius: 8px;
      }}
      
      .category-header {{
        padding: 15px 20px;
      }}
      
      .category-title {{
        font-size: 18px;
      }}
      
      .category-news {{
        padding: 15px;
      }}
      
      .news-item {{
        padding: 15px;
        margin-bottom: 15px;
        border-radius: 6px;
      }}
      
      .news-title {{
        font-size: 16px;
        margin-bottom: 10px;
        line-height: 1.3;
      }}
      
      .news-meta {{
        flex-direction: column;
        align-items: flex-start;
        gap: 6px;
        margin-top: 6px;
      }}
      
      .news-source,
      .region-badge,
      .impact-badge,
      .content-quality-badge {{
        font-size: 10px;
        padding: 3px 6px;
        margin: 2px 4px 2px 0;
      }}
      
      .news-summary {{
        font-size: 13px;
        line-height: 1.5;
        margin-bottom: 10px;
      }}
      
      .key-points {{
        margin: 10px 0;
        padding-left: 15px;
        font-size: 12px;
      }}
      
      .key-points li {{
        margin-bottom: 3px;
        line-height: 1.3;
      }}
      
      .footer {{
        padding: 15px;
        border-radius: 0;
        font-size: 12px;
      }}
    }}
    
    /* è¶…å°å±å¹•é€‚é… (iPhone SEç­‰) */
    @media (max-width: 480px) {{
      .container {{
        padding: 5px;
      }}
      
      .header {{
        padding: 15px 10px;
      }}
      
      .logo {{
        width: 120px;
      }}
      
      .title {{
        font-size: 20px;
      }}
      
      .subtitle {{
        font-size: 12px;
      }}
      
      .content {{
        padding: 15px 10px;
      }}
      
      .stats-grid {{
        grid-template-columns: 1fr;
        gap: 8px;
      }}
      
      .stat-card {{
        padding: 12px;
      }}
      
      .stat-number {{
        font-size: 20px;
      }}
      
      .category-title {{
        font-size: 16px;
      }}
      
      .news-title {{
        font-size: 14px;
      }}
      
      .news-summary {{
        font-size: 12px;
      }}
    }}
    
    /* æ¨ªå±é€‚é… */
    @media (max-width: 768px) and (orientation: landscape) {{
      .stats-grid {{
        grid-template-columns: repeat(4, 1fr);
      }}
      
      .category-section {{
        margin-bottom: 20px;
      }}
      
      .news-item {{
        padding: 12px;
        margin-bottom: 12px;
      }}
    }}
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <svg class="logo" viewBox="0 0 400 120" xmlns="http://www.w3.org/2000/svg">
        <defs>
          <linearGradient id="logoGradient" x1="0%" y1="0%" x2="100%" y2="100%">
            <stop offset="0%" style="stop-color:#8B5CF6;stop-opacity:1" />
            <stop offset="50%" style="stop-color:#3B82F6;stop-opacity:1" />
            <stop offset="100%" style="stop-color:#06B6D4;stop-opacity:1" />
          </linearGradient>
        </defs>
        <circle cx="40" cy="60" r="25" fill="url(#logoGradient)" opacity="0.8"/>
        <circle cx="25" cy="35" r="15" fill="url(#logoGradient)" opacity="0.9"/>
        <circle cx="55" cy="35" r="12" fill="url(#logoGradient)" opacity="0.7"/>
        <circle cx="35" cy="75" r="10" fill="url(#logoGradient)" opacity="0.6"/>
        <circle cx="60" cy="75" r="8" fill="url(#logoGradient)" opacity="0.8"/>
        <text x="90" y="45" font-family="Arial, sans-serif" font-size="24" font-weight="bold" fill="#3b82f6">ocean security</text>
        <text x="90" y="70" font-family="Arial, sans-serif" font-size="12" fill="#94a3b8">æµ·ä¹‹å®‰ï¼Œæ•°å­—å®‰å…¨ä¸“å®¶</text>
      </svg>
      <h1 class="title">æµ·ä¹‹å®‰ç½‘ç»œå®‰å…¨æ—¥æŠ¥</h1>
      <div class="subtitle">{current_time} Â· AIæ™ºèƒ½ç”Ÿæˆ</div>
    </div>
    
    <div class="content">
      <div class="summary-section">
        <h2 class="summary-title">ä»Šæ—¥æ‘˜è¦</h2>
        <div class="summary-content">{analysis_result.get('summary', 'ä»Šæ—¥æš‚æ— ç½‘ç»œå®‰å…¨æ–°é—»æ‘˜è¦')}</div>
      </div>
"""
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ - åŒ…å«å¢å¼ºçˆ¬è™«çš„æ•ˆæœç»Ÿè®¡
        sources = analysis_result.get('sources', [])
        regions = analysis_result.get('regions', [])
        languages = analysis_result.get('languages', [])
        enhanced_count = analysis_result.get('enhanced_count', 0)
        total_chars = analysis_result.get('total_chars', 0)
        
        html_template += f"""
      <div class="stats-section">
        <div class="stats-grid">
          <div class="stat-card">
            <div class="stat-number">{analysis_result.get('total_news', 0)}</div>
            <div class="stat-label">ç²¾é€‰æ–°é—»</div>
            <div class="stat-detail">ä»{analysis_result.get('original_count', 0)}æ¡ä¸­ç²¾é€‰</div>
          </div>
          <div class="stat-card">
            <div class="stat-number">{enhanced_count}</div>
            <div class="stat-label">å¢å¼ºå†…å®¹</div>
            <div class="stat-detail">æ·±åº¦æŠ“å–æˆåŠŸ</div>
          </div>
          <div class="stat-card">
            <div class="stat-number">{total_chars:,}</div>
            <div class="stat-label">å†…å®¹å­—ç¬¦</div>
            <div class="stat-detail">ä¸°å¯Œå¯è¯»</div>
          </div>
          <div class="stat-card">
            <div class="stat-number">4</div>
            <div class="stat-label">åˆ†æç»´åº¦</div>
            <div class="stat-detail">é£é™©Â·äº‹ä»¶Â·èˆ†æƒ…Â·è¶‹åŠ¿</div>
          </div>
        </div>
        <div class="enhancement-info">
          <h3>ğŸš€ å†…å®¹å¢å¼ºæ•ˆæœ</h3>
          <div class="enhancement-stats">
            <div class="enhancement-item">
              <span class="enhancement-label">æ·±åº¦æŠ“å–æˆåŠŸç‡:</span>
              <span class="enhancement-value">{(enhanced_count/analysis_result.get('total_news', 1)*100):.1f}%</span>
            </div>
            <div class="enhancement-item">
              <span class="enhancement-label">å¹³å‡å†…å®¹é•¿åº¦:</span>
              <span class="enhancement-value">{total_chars//analysis_result.get('total_news', 1):,}å­—ç¬¦</span>
            </div>
            <div class="enhancement-item">
              <span class="enhancement-label">å†…å®¹è´¨é‡:</span>
              <span class="enhancement-value">{'ä¼˜ç§€' if enhanced_count > 5 else 'è‰¯å¥½' if enhanced_count > 2 else 'ä¸€èˆ¬'}</span>
            </div>
          </div>
        </div>
        <div class="source-list">
          <h3>ğŸ“° å…¨çƒæ–°é—»æ¥æº</h3>
          <div class="source-tags">
"""
        
        # æ·»åŠ æ¥æºæ ‡ç­¾
        for source in sources:
            html_template += f'<span class="source-tag">{source}</span>'
        
        html_template += """
          </div>
        </div>
      </div>
"""
        
        # æ·»åŠ åˆ†ç±»æ–°é—» - å››ç»´åº¦åˆ†ç±»
        icon_map = {
            "å®‰å…¨é£é™©": "icon-risk",
            "å®‰å…¨äº‹ä»¶": "icon-event", 
            "å®‰å…¨èˆ†æƒ…": "icon-opinion",
            "å®‰å…¨è¶‹åŠ¿": "icon-trend"
        }
        
        for category, news_items in analysis_result.get('categories', {}).items():
            if news_items:
                icon_class = icon_map.get(category, "icon-focus")
                html_template += f"""
      <div class="category-section">
        <div class="category-header">
          <h2 class="category-title {icon_class}">{category}</h2>
        </div>
        <div class="category-news">
"""
                
                for item in news_items:
                    impact_level = item.get('impact_level', 'ä¸­')
                    impact_class = {
                        'é«˜': 'impact-high',
                        'ä¸­': 'impact-medium', 
                        'ä½': 'impact-low'
                    }.get(impact_level, 'impact-medium')
                    
                    # å¤„ç†å…³é”®ç‚¹åˆ—è¡¨
                    key_points_html = ""
                    if item.get('key_points'):
                        key_points_html = "<ul class='key-points'>"
                        for point in item['key_points'][:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªå…³é”®ç‚¹
                            key_points_html += f"<li>{point}</li>"
                        key_points_html += "</ul>"
                    
                    # æ·»åŠ å†…å®¹è´¨é‡æ ‡è¯†
                    quality_badge = ""
                    if hasattr(item, 'enhanced_content') and item.get('enhanced_content'):
                        quality_badge = '<span class="content-quality-badge quality-enhanced">æ·±åº¦å†…å®¹</span>'
                    elif item.get('char_count', 0) > 500:
                        quality_badge = '<span class="content-quality-badge quality-rss">RSSå†…å®¹</span>'
                    else:
                        quality_badge = '<span class="content-quality-badge quality-failed">ç®€è¦å†…å®¹</span>'
                    
                    html_template += f"""          <div class="news-item">
            <div class="news-header">
              <div class="news-title">{item['title']}{quality_badge}</div>
              <div class="news-meta">
                <span class="news-source">{item.get('source', 'æœªçŸ¥æ¥æº')}</span>
                <span class="region-badge">{item.get('region', 'Unknown')}</span>
                <span class="impact-badge {impact_class}">å½±å“: {impact_level}</span>
              </div>
            </div>
            <div class="news-summary">
              <strong>å†…å®¹è¦ç´ ï¼š</strong>{item.get('summary', 'æš‚æ— è¯¦ç»†æ€»ç»“')}
            </div>
            {key_points_html}
          </div>
"""
                
                html_template += """        </div>
      </div>
"""
        
        # æ·»åŠ footer
        html_template += f"""    </div>
    
    <div class="footer">
      <p>Â© 2025 æµ·ä¹‹å®‰ï¼ˆä¸­å›½ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸ | åŸºäºæ™ºè°±GLM AIç”Ÿæˆ</p>
      <p>å…±åˆ†æ {analysis_result.get('total_news', 0)} æ¡å®‰å…¨æ–°é—» | å®˜ç½‘ï¼š<a href="https://www.oceansecurity.cn" style="color: #3b82f6;">www.oceansecurity.cn</a></p>
    </div>
  </div>
</body>
</html>"""
        
        # ç¡®ä¿åŒ…å«ç§»åŠ¨ç«¯æ ·å¼ä¿æŠ¤
        try:
            from style_protection import ensure_mobile_responsive
            html_template = ensure_mobile_responsive(html_template)
            logger.info("âœ… ç§»åŠ¨ç«¯æ ·å¼ä¿æŠ¤å·²åº”ç”¨")
        except ImportError:
            # å¦‚æœä¿æŠ¤æ¨¡å—ä¸å¯ç”¨ï¼Œæ‰‹åŠ¨æ£€æŸ¥å’Œæ·»åŠ 
            if "@media (max-width: 768px)" not in html_template:
                fallback_css = self._get_fallback_mobile_css()
                html_template = html_template.replace("</style>", fallback_css + "\n  </style>")
                logger.info("âœ… å¤‡ç”¨ç§»åŠ¨ç«¯æ ·å¼å·²åº”ç”¨")
        
        return html_template
    
    def _get_fallback_mobile_css(self) -> str:
        """
        å¤‡ç”¨ç§»åŠ¨ç«¯CSSæ ·å¼
        """
        return """
    /* ç§»åŠ¨ç«¯é€‚é…æ ·å¼ - é‡è¦ï¼šè¯·å‹¿åˆ é™¤æˆ–è¦†ç›– */
    @media (max-width: 768px) {
      .container { margin: 0; padding: 10px; border-radius: 0; }
      .header { padding: 20px 15px; border-radius: 0; }
      .logo { width: 150px; margin-bottom: 15px; }
      .title { font-size: 24px; margin-bottom: 12px; }
      .subtitle { font-size: 14px; margin-bottom: 6px; }
      .content { padding: 20px 15px; }
      .summary-section { padding: 15px; margin-bottom: 20px; border-radius: 8px; }
      .summary-title { font-size: 16px; margin-bottom: 12px; }
      .summary-content { font-size: 14px; line-height: 1.6; }
      .stats-grid { grid-template-columns: repeat(2, 1fr); gap: 10px; }
      .stat-card { padding: 15px; border-radius: 8px; }
      .stat-number { font-size: 24px; margin-bottom: 6px; }
      .stat-label { font-size: 12px; }
      .category-section { margin-bottom: 25px; border-radius: 8px; }
      .category-header { padding: 15px 20px; }
      .category-title { font-size: 18px; }
      .category-news { padding: 15px; }
      .news-item { padding: 15px; margin-bottom: 15px; border-radius: 6px; }
      .news-title { font-size: 16px; margin-bottom: 10px; line-height: 1.3; }
      .news-meta { flex-direction: column; align-items: flex-start; gap: 6px; margin-top: 6px; }
      .news-source, .region-badge, .impact-badge, .content-quality-badge { font-size: 10px; padding: 3px 6px; margin: 2px 4px 2px 0; }
      .news-summary { font-size: 13px; line-height: 1.5; margin-bottom: 10px; }
      .key-points { margin: 10px 0; padding-left: 15px; font-size: 12px; }
      .key-points li { margin-bottom: 3px; line-height: 1.3; }
      .footer { padding: 15px; border-radius: 0; font-size: 12px; }
    }
    @media (max-width: 480px) {
      .container { padding: 5px; }
      .header { padding: 15px 10px; }
      .logo { width: 120px; }
      .title { font-size: 20px; }
      .subtitle { font-size: 12px; }
      .content { padding: 15px 10px; }
      .stats-grid { grid-template-columns: 1fr; gap: 8px; }
      .stat-card { padding: 12px; }
      .stat-number { font-size: 20px; }
      .category-title { font-size: 16px; }
      .news-title { font-size: 14px; }
      .news-summary { font-size: 12px; }
    }
        """
    
    def generate_daily_report(self, days_back: int = 1) -> str:
        """
        ç”Ÿæˆæ¯æ—¥å®‰å…¨å¿«æŠ¥
        
        Args:
            days_back: ç”Ÿæˆå‡ å¤©å‰çš„æŠ¥å‘Š
            
        Returns:
            ç”Ÿæˆçš„HTMLæ–‡ä»¶è·¯å¾„
        """
        try:
            # 1. æŠ“å–æ–°é—»
            news_list = self.fetch_security_news(days_back)
            
            if not news_list:
                logger.warning("æœªè·å–åˆ°ä»»ä½•æ–°é—»ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                return ""
            
            # 2. ä½¿ç”¨GLMç”Ÿæˆåˆ†æ
            logger.info("æ­£åœ¨ä½¿ç”¨GLMç”Ÿæˆæ–°é—»åˆ†æ...")
            analysis_result = self.generate_news_analysis(news_list)
            
            # 3. ç”ŸæˆHTMLæŠ¥å‘Š
            target_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y%m%d')
            html_content = self.generate_html_report(analysis_result, target_date)
            
            # 4. ä¿å­˜æ–‡ä»¶
            filename = f"news{target_date}.html"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"âœ… æˆåŠŸç”ŸæˆAIæ™ºèƒ½æ–°é—»å¿«æŠ¥: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""

def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥ï¼Œæˆ–è€…åœ¨è¿™é‡Œç›´æ¥è®¾ç½®
    api_key = os.getenv('GLM_API_KEY')
    
    if not api_key:
        print("âš ï¸  è¯·è®¾ç½®GLM_API_KEYç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­é…ç½®APIå¯†é’¥")
        print("è·å–APIå¯†é’¥ï¼šhttps://open.bigmodel.cn/")
        return
    
    generator = GLMNewsGenerator(api_key)
    
    # ç”Ÿæˆæ˜¨å¤©çš„æ–°é—»å¿«æŠ¥
    result = generator.generate_daily_report(days_back=1)
    
    if result:
        print(f"ğŸ‰ AIæ™ºèƒ½æ–°é—»å¿«æŠ¥ç”ŸæˆæˆåŠŸ: {result}")
    else:
        print("âŒ æ–°é—»å¿«æŠ¥ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()