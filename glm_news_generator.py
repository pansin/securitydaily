#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºæ™ºè°±GLMçš„ç½‘ç»œå®‰å…¨æ–°é—»ç”Ÿæˆå™¨
å‚è€ƒï¼šhttps://docs.bigmodel.cn/cn/best-practice/creativepractice/aimorningnewspaper
"""

import requests
import json
from datetime import datetime, timedelta
import logging
import os
from typing import List, Dict
import feedparser
from bs4 import BeautifulSoup
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('glm_news.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class GLMNewsGenerator:
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–GLMæ–°é—»ç”Ÿæˆå™¨
        
        Args:
            api_key: æ™ºè°±GLM APIå¯†é’¥
        """
        self.api_key = api_key or os.getenv('GLM_API_KEY')
        self.base_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ–°é—»æºé…ç½®
        self.news_sources = [
            {
                'name': 'å®‰å…¨å®¢',
                'rss_url': 'https://api.anquanke.com/data/v1/rss',
                'weight': 1.0
            },
            {
                'name': 'FreeBuf',
                'rss_url': 'https://www.freebuf.com/feed',
                'weight': 1.0
            },
            {
                'name': 'å˜¶å¼',
                'rss_url': 'https://www.4hou.com/feed',
                'weight': 1.0
            }
        ]
        
        self.security_keywords = [
            'å®‰å…¨', 'æ¼æ´', 'æ”»å‡»', 'é»‘å®¢', 'ç—…æ¯’', 'æ¶æ„è½¯ä»¶', 'å‹’ç´¢', 'æ¸—é€',
            'é˜²æŠ¤', 'é˜²å¾¡', 'åŠ å¯†', 'è§£å¯†', 'éšç§', 'æ•°æ®æ³„éœ²', 'ç½‘ç»œå®‰å…¨',
            'APT', 'DDoS', 'é’“é±¼', 'æœ¨é©¬', 'åé—¨', 'ææƒ', 'CVE', 'RCE'
        ]
    
    def call_glm_api(self, prompt: str, model: str = "glm-4-flash") -> str:
        """
        è°ƒç”¨æ™ºè°±GLM API
        
        Args:
            prompt: è¾“å…¥æç¤ºè¯
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
        """
        try:
            payload = {
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.7,
                "max_tokens": 2000
            }
            
            response = requests.post(
                self.base_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                logger.error(f"GLM APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return ""
                
        except Exception as e:
            logger.error(f"GLM APIè°ƒç”¨å¼‚å¸¸: {e}")
            return ""
    
    def fetch_article_content(self, url: str, max_length: int = 2000) -> str:
        """
        æŠ“å–æ–‡ç« å®Œæ•´å†…å®¹
        
        Args:
            url: æ–‡ç« é“¾æ¥
            max_length: æœ€å¤§å†…å®¹é•¿åº¦
            
        Returns:
            æ–‡ç« å†…å®¹
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'advertisement']):
                tag.decompose()
            
            # å°è¯•æ‰¾åˆ°ä¸»è¦å†…å®¹åŒºåŸŸ
            content_selectors = [
                'article', '.article-content', '.post-content', '.entry-content',
                '.content', '.main-content', '.article-body', '.post-body',
                '[role="main"]', '.story-body', '.article-text'
            ]
            
            content = ""
            for selector in content_selectors:
                elements = soup.select(selector)
                if elements:
                    content = elements[0].get_text(strip=True)
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šçš„å†…å®¹åŒºåŸŸï¼Œä½¿ç”¨æ•´ä¸ªbody
            if not content:
                body = soup.find('body')
                if body:
                    content = body.get_text(strip=True)
            
            # æ¸…ç†å’Œæˆªæ–­å†…å®¹
            if content:
                # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
                content = ' '.join(content.split())
                # æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦
                if len(content) > max_length:
                    content = content[:max_length] + "..."
            
            return content
            
        except Exception as e:
            logger.warning(f"æŠ“å–æ–‡ç« å†…å®¹å¤±è´¥ {url}: {e}")
            return ""
    
    def fetch_security_news(self, days_back: int = 1) -> List[Dict]:
        """
        æŠ“å–ç½‘ç»œå®‰å…¨æ–°é—»
        
        Args:
            days_back: æŠ“å–å‡ å¤©å‰çš„æ–°é—»
            
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        target_date = (datetime.now() - timedelta(days=days_back)).date()
        all_news = []
        
        logger.info(f"å¼€å§‹æŠ“å– {target_date} çš„ç½‘ç»œå®‰å…¨æ–°é—»...")
        
        for source in self.news_sources:
            if not source.get('enabled', True):
                continue
                
            try:
                logger.info(f"æ­£åœ¨æŠ“å– {source['name']} ({source.get('region', 'Unknown')}) çš„RSSæº...")
                
                # è®¾ç½®è¯·æ±‚å¤´
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                
                # è·å–RSSå†…å®¹
                response = requests.get(source['rss_url'], headers=headers, timeout=15)
                feed = feedparser.parse(response.content)
                source_news = []
                
                for entry in feed.entries:
                    # è§£æå‘å¸ƒæ—¶é—´
                    pub_date = None
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        pub_date = datetime(*entry.published_parsed[:6]).date()
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        pub_date = datetime(*entry.updated_parsed[:6]).date()
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç›®æ ‡æ—¥æœŸçš„æ–°é—»ï¼ˆå…è®¸3å¤©å†…çš„æ–°é—»ï¼‰
                    if pub_date and (datetime.now().date() - pub_date).days <= 3:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºå®‰å…¨ç›¸å…³æ–°é—»
                        title = entry.title.lower()
                        summary = getattr(entry, 'summary', '').lower()
                        
                        # æ‰©å±•å…³é”®è¯åŒ¹é…é€»è¾‘
                        is_security_related = any(keyword.lower() in title or keyword.lower() in summary 
                                                for keyword in self.security_keywords)
                        
                        if is_security_related:
                            # è·å–æ–‡ç« å®Œæ•´å†…å®¹
                            full_content = ""
                            if hasattr(entry, 'content') and entry.content:
                                # RSSä¸­åŒ…å«å†…å®¹
                                full_content = entry.content[0].value if isinstance(entry.content, list) else str(entry.content)
                                # æ¸…ç†HTMLæ ‡ç­¾
                                soup = BeautifulSoup(full_content, 'html.parser')
                                full_content = soup.get_text(strip=True)
                            elif entry.link:
                                # æŠ“å–å®Œæ•´æ–‡ç« å†…å®¹
                                logger.info(f"æ­£åœ¨æŠ“å–æ–‡ç« å†…å®¹: {entry.title[:50]}...")
                                full_content = self.fetch_article_content(entry.link)
                            
                            news_item = {
                                'title': entry.title,
                                'link': entry.link,
                                'summary': getattr(entry, 'summary', ''),
                                'content': full_content,
                                'published_date': pub_date,
                                'source': source['name'],
                                'weight': source['weight'],
                                'language': source.get('language', 'en'),
                                'region': source.get('region', 'Unknown')
                            }
                            source_news.append(news_item)
                
                logger.info(f"ä» {source['name']} è·å–åˆ° {len(source_news)} æ¡å®‰å…¨æ–°é—»")
                all_news.extend(source_news)
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(2)
                
            except Exception as e:
                logger.error(f"æŠ“å– {source['name']} å¤±è´¥: {e}")
                continue
        
        # å»é‡å’Œæ’åº
        unique_news = []
        seen_titles = set()
        
        for news in all_news:
            # ä½¿ç”¨æ ‡é¢˜çš„å‰50ä¸ªå­—ç¬¦è¿›è¡Œå»é‡ï¼Œé¿å…å®Œå…¨ç›¸åŒçš„æ ‡é¢˜
            title_key = news['title'][:50].lower()
            if title_key not in seen_titles:
                unique_news.append(news)
                seen_titles.add(title_key)
        
        # æŒ‰æƒé‡å’Œæ—¶é—´æ’åºï¼Œå–å‰15æ¡ï¼ˆå¢åŠ æ•°é‡ä»¥è·å¾—æ›´å¥½çš„é€‰æ‹©ï¼‰
        unique_news.sort(key=lambda x: (x['weight'], x['published_date']), reverse=True)
        
        logger.info(f"æ€»å…±è·å–åˆ° {len(unique_news)} æ¡ä¸é‡å¤çš„å®‰å…¨æ–°é—»")
        return unique_news[:15]
    
    def generate_news_analysis(self, news_list: List[Dict]) -> Dict:
        """
        ä½¿ç”¨GLMç”Ÿæˆæ–°é—»åˆ†æå’Œæ‘˜è¦
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            åŒ…å«åˆ†æå†…å®¹çš„å­—å…¸
        """
        if not news_list:
            return {"summary": "ä»Šæ—¥æš‚æ— ç½‘ç»œå®‰å…¨æ–°é—»", "categories": {}}
        
        # æ„å»ºåŒ…å«å†…å®¹çš„æ–°é—»ä¿¡æ¯
        news_details = []
        for i, news in enumerate(news_list):
            content_preview = ""
            if news.get('content'):
                # å–å†…å®¹çš„å‰300å­—ç¬¦ä½œä¸ºé¢„è§ˆ
                content_preview = news['content'][:300] + "..." if len(news['content']) > 300 else news['content']
            elif news.get('summary'):
                content_preview = news['summary']
            
            news_detail = f"{i+1}. ã€{news['source']}ã€‘{news['title']}\n"
            if content_preview:
                news_detail += f"   å†…å®¹æ‘˜è¦: {content_preview}\n"
            news_details.append(news_detail)
        
        news_text = "\n".join(news_details)
        
        # ç”Ÿæˆä»Šæ—¥æ‘˜è¦
        summary_prompt = f"""
è¯·åŸºäºä»¥ä¸‹å…¨çƒç½‘ç»œå®‰å…¨æ–°é—»ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä»Šæ—¥å…¨çƒå®‰å…¨æ€åŠ¿æ‘˜è¦ï¼ˆ250å­—ä»¥å†…ï¼‰ï¼š

{news_text}

è¦æ±‚ï¼š
1. æ€»ç»“å…¨çƒç½‘ç»œå®‰å…¨æ€åŠ¿çš„ä¸»è¦ç‰¹ç‚¹å’Œè¶‹åŠ¿
2. çªå‡ºé‡ç‚¹å¨èƒã€æ”»å‡»äº‹ä»¶å’ŒæŠ€æœ¯å‘å±•
3. ä½“ç°å›½é™…è§†é‡å’Œä¸“ä¸šæ·±åº¦
4. è¯­è¨€ä¸“ä¸šã€æƒå¨ã€ç®€æ´
5. å¿…é¡»ä½¿ç”¨ä¸­æ–‡å›ç­”
"""
        
        summary = self.call_glm_api(summary_prompt)
        
        # å¯¹æ–°é—»è¿›è¡Œæ™ºèƒ½åˆ†ç±»åˆ†æ
        category_prompt = f"""
è¯·å°†ä»¥ä¸‹å…¨çƒç½‘ç»œå®‰å…¨æ–°é—»æŒ‰ç…§å¨èƒç±»å‹è¿›è¡Œæ™ºèƒ½åˆ†ç±»ï¼Œå¹¶ä¸ºæ¯æ¡æ–°é—»ç”Ÿæˆ80å­—ä»¥å†…çš„ä¸“ä¸šæ·±åº¦åˆ†æï¼š

{news_text}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
{{
    "é‡å¤§å®‰å…¨äº‹ä»¶": [
        {{"title": "æ–°é—»æ ‡é¢˜", "analysis": "æ·±åº¦åˆ†æå†…å®¹", "source": "æ–°é—»æ¥æº", "severity": "å¨èƒç­‰çº§"}}
    ],
    "æ¼æ´ä¸å¨èƒæƒ…æŠ¥": [
        {{"title": "æ–°é—»æ ‡é¢˜", "analysis": "æ·±åº¦åˆ†æå†…å®¹", "source": "æ–°é—»æ¥æº", "severity": "å¨èƒç­‰çº§"}}
    ],
    "æŠ€æœ¯ä¸äº§ä¸šåŠ¨æ€": [
        {{"title": "æ–°é—»æ ‡é¢˜", "analysis": "æ·±åº¦åˆ†æå†…å®¹", "source": "æ–°é—»æ¥æº", "severity": "å¨èƒç­‰çº§"}}
    ],
    "æ”¿ç­–ä¸åˆè§„": [
        {{"title": "æ–°é—»æ ‡é¢˜", "analysis": "æ·±åº¦åˆ†æå†…å®¹", "source": "æ–°é—»æ¥æº", "severity": "å¨èƒç­‰çº§"}}
    ]
}}

åˆ†ç±»æ ‡å‡†ï¼š
- é‡å¤§å®‰å…¨äº‹ä»¶ï¼šæ•°æ®æ³„éœ²ã€ç½‘ç»œæ”»å‡»ã€å®‰å…¨äº‹æ•…ç­‰
- æ¼æ´ä¸å¨èƒæƒ…æŠ¥ï¼šCVEæ¼æ´ã€æ¶æ„è½¯ä»¶ã€æ”»å‡»æŠ€æœ¯ã€å¨èƒåˆ†æç­‰
- æŠ€æœ¯ä¸äº§ä¸šåŠ¨æ€ï¼šå®‰å…¨äº§å“ã€æŠ€æœ¯åˆ›æ–°ã€è¡Œä¸šå‘å±•ã€æŠ•èµ„å¹¶è´­ç­‰
- æ”¿ç­–ä¸åˆè§„ï¼šæ³•å¾‹æ³•è§„ã€æ”¿ç­–æ ‡å‡†ã€åˆè§„è¦æ±‚ç­‰

å¨èƒç­‰çº§ï¼šé«˜å±ã€ä¸­å±ã€ä½å±ã€ä¿¡æ¯

è¦æ±‚ï¼š
1. åˆ†æè¦æ·±å…¥ä¸“ä¸šï¼Œä½“ç°æŠ€æœ¯æ·±åº¦
2. çªå‡ºæ–°é—»çš„é‡è¦æ€§ã€å½±å“èŒƒå›´å’Œåº”å¯¹å»ºè®®
3. å¨èƒç­‰çº§è¯„ä¼°è¦å‡†ç¡®
4. å¿…é¡»ä½¿ç”¨ä¸­æ–‡å›ç­”
5. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®
"""
        
        category_result = self.call_glm_api(category_prompt)
        
        # è§£æåˆ†ç±»ç»“æœ
        categories = {}
        try:
            categories = json.loads(category_result)
        except Exception as e:
            logger.warning(f"åˆ†ç±»ç»“æœè§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»")
            # é»˜è®¤åˆ†ç±»é€»è¾‘
            categories = self._default_categorize_news(news_list)
        
        return {
            "summary": summary,
            "categories": categories,
            "total_news": len(news_list),
            "sources": list(set([news['source'] for news in news_list])),
            "regions": list(set([news.get('region', 'Unknown') for news in news_list]))
        }
    
    def _default_categorize_news(self, news_list: List[Dict]) -> Dict:
        """
        é»˜è®¤æ–°é—»åˆ†ç±»é€»è¾‘ï¼ˆå½“AIåˆ†ç±»å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        """
        categories = {
            "é‡å¤§å®‰å…¨äº‹ä»¶": [],
            "æ¼æ´ä¸å¨èƒæƒ…æŠ¥": [],
            "æŠ€æœ¯ä¸äº§ä¸šåŠ¨æ€": [],
            "æ”¿ç­–ä¸åˆè§„": []
        }
        
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†ç±»
        for news in news_list:
            title_lower = news['title'].lower()
            content_lower = (news.get('content', '') + news.get('summary', '')).lower()
            
            analysis = f"æ¥æºï¼š{news['source']} | " + (news.get('summary', 'æš‚æ— è¯¦ç»†æ‘˜è¦')[:100] + "..." if len(news.get('summary', '')) > 100 else news.get('summary', 'æš‚æ— è¯¦ç»†æ‘˜è¦'))
            
            item = {
                "title": news['title'],
                "analysis": analysis,
                "source": news['source'],
                "severity": "ä¸­å±"
            }
            
            # ç®€å•çš„å…³é”®è¯åˆ†ç±»
            if any(keyword in title_lower or keyword in content_lower for keyword in 
                   ['breach', 'attack', 'hack', 'æ”»å‡»', 'æ³„éœ²', 'å…¥ä¾µ', 'å‹’ç´¢']):
                categories["é‡å¤§å®‰å…¨äº‹ä»¶"].append(item)
            elif any(keyword in title_lower or keyword in content_lower for keyword in 
                     ['vulnerability', 'cve', 'exploit', 'æ¼æ´', 'å¨èƒ', 'malware']):
                categories["æ¼æ´ä¸å¨èƒæƒ…æŠ¥"].append(item)
            elif any(keyword in title_lower or keyword in content_lower for keyword in 
                     ['policy', 'regulation', 'compliance', 'æ”¿ç­–', 'æ³•è§„', 'åˆè§„']):
                categories["æ”¿ç­–ä¸åˆè§„"].append(item)
            else:
                categories["æŠ€æœ¯ä¸äº§ä¸šåŠ¨æ€"].append(item)
        
        return categories
    
    def generate_html_report(self, analysis_result: Dict, date_str: str) -> str:
        """
        ç”ŸæˆHTMLæ ¼å¼çš„æ–°é—»å¿«æŠ¥
        
        Args:
            analysis_result: åˆ†æç»“æœ
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            
        Returns:
            HTMLå†…å®¹
        """
        current_time = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        html_template = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>æµ·ä¹‹å®‰ç½‘ç»œå®‰å…¨æ—¥æŠ¥ - {current_time}</title>
  
  <style>
    * {{
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }}
    
    body {{
      font-family: 'Microsoft YaHei', 'SimHei', 'Arial', sans-serif;
      background: linear-gradient(135deg, #0f172a 0%, #1e293b 50%, #334155 100%);
      color: #f1f5f9;
      min-height: 100vh;
      padding: 20px;
      line-height: 1.6;
    }}
    
    .container {{
      max-width: 1200px;
      margin: 0 auto;
      background: rgba(15, 23, 42, 0.95);
      border: 1px solid rgba(59, 130, 246, 0.3);
      border-radius: 16px;
      box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.8);
      overflow: hidden;
    }}
    
    .header {{
      background: linear-gradient(90deg, rgba(59, 130, 246, 0.1) 0%, rgba(147, 51, 234, 0.1) 100%);
      border-bottom: 1px solid rgba(59, 130, 246, 0.3);
      padding: 40px;
      text-align: center;
      position: relative;
    }}
    
    .header::before {{
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 2px;
      background: linear-gradient(90deg, #3b82f6, #8b5cf6, #06b6d4);
    }}
    
    .logo {{
      width: 200px;
      height: auto;
      margin-bottom: 20px;
    }}
    
    .title {{
      font-size: 36px;
      font-weight: 700;
      background: linear-gradient(135deg, #3b82f6, #8b5cf6);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      margin-bottom: 16px;
    }}
    
    .subtitle {{
      font-size: 18px;
      color: #94a3b8;
      margin-bottom: 8px;
    }}
    
    .content {{
      padding: 40px;
    }}
    
    .summary-section {{
      background: rgba(30, 41, 59, 0.8);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 12px;
      padding: 24px;
      margin-bottom: 32px;
    }}
    
    .summary-title {{
      font-size: 20px;
      font-weight: 600;
      color: #3b82f6;
      margin-bottom: 16px;
      display: flex;
      align-items: center;
      gap: 8px;
    }}
    
    .summary-title::before {{
      content: 'ğŸ“Š';
      font-size: 24px;
    }}
    
    .summary-content {{
      color: #cbd5e1;
      line-height: 1.8;
      font-size: 16px;
    }}
    
    .category-section {{
      margin-bottom: 40px;
      background: rgba(30, 41, 59, 0.4);
      border-radius: 12px;
      border: 1px solid rgba(59, 130, 246, 0.15);
      overflow: hidden;
    }}
    
    .category-header {{
      background: linear-gradient(135deg, rgba(59, 130, 246, 0.2), rgba(147, 51, 234, 0.2));
      padding: 20px 24px;
      border-bottom: 1px solid rgba(59, 130, 246, 0.3);
    }}
    
    .category-title {{
      font-size: 24px;
      font-weight: 600;
      color: #e2e8f0;
      display: flex;
      align-items: center;
      gap: 12px;
    }}
    
    .category-news {{
      padding: 24px;
    }}
    
    .news-item {{
      background: rgba(51, 65, 85, 0.6);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      transition: all 0.3s ease;
      position: relative;
    }}
    
    .news-item::before {{
      content: '';
      position: absolute;
      left: 0;
      top: 0;
      bottom: 0;
      width: 4px;
      background: linear-gradient(180deg, #3b82f6, #8b5cf6);
      border-radius: 2px 0 0 2px;
    }}
    
    .news-item:hover {{
      border-color: rgba(59, 130, 246, 0.4);
      box-shadow: 0 4px 12px rgba(59, 130, 246, 0.15);
    }}
    
    .news-title {{
      font-size: 18px;
      font-weight: 600;
      color: #f1f5f9;
      margin-bottom: 12px;
      line-height: 1.4;
    }}
    
    .news-analysis {{
      color: #cbd5e1;
      line-height: 1.7;
      font-size: 15px;
    }}
    
    .footer {{
      background: rgba(15, 23, 42, 0.8);
      border-top: 1px solid rgba(59, 130, 246, 0.3);
      padding: 24px 40px;
      text-align: center;
      color: #64748b;
      font-size: 14px;
    }}
    
    .stats-section {{
      margin-bottom: 32px;
    }}
    
    .stats-grid {{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 20px;
      margin-bottom: 20px;
    }}
    
    .stat-card {{
      background: rgba(30, 41, 59, 0.8);
      border: 1px solid rgba(59, 130, 246, 0.2);
      border-radius: 12px;
      padding: 20px;
      text-align: center;
      transition: all 0.3s ease;
    }}
    
    .stat-card:hover {{
      border-color: rgba(59, 130, 246, 0.4);
      transform: translateY(-2px);
    }}
    
    .stat-number {{
      font-size: 32px;
      font-weight: 700;
      color: #3b82f6;
      margin-bottom: 8px;
    }}
    
    .stat-label {{
      font-size: 14px;
      color: #94a3b8;
    }}
    
    .news-header {{
      margin-bottom: 12px;
    }}
    
    .news-meta {{
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-top: 8px;
      font-size: 12px;
    }}
    
    .news-source {{
      color: #94a3b8;
      background: rgba(59, 130, 246, 0.1);
      padding: 4px 8px;
      border-radius: 4px;
    }}
    
    .severity-badge {{
      padding: 4px 8px;
      border-radius: 4px;
      font-weight: 600;
      font-size: 11px;
    }}
    
    .severity-high {{
      background: rgba(239, 68, 68, 0.2);
      color: #fca5a5;
      border: 1px solid rgba(239, 68, 68, 0.3);
    }}
    
    .severity-medium {{
      background: rgba(245, 158, 11, 0.2);
      color: #fbbf24;
      border: 1px solid rgba(245, 158, 11, 0.3);
    }}
    
    .severity-low {{
      background: rgba(34, 197, 94, 0.2);
      color: #86efac;
      border: 1px solid rgba(34, 197, 94, 0.3);
    }}
    
    .severity-info {{
      background: rgba(59, 130, 246, 0.2);
      color: #93c5fd;
      border: 1px solid rgba(59, 130, 246, 0.3);
    }}
    
    .icon-critical::before {{ content: 'ğŸš¨'; }}
    .icon-focus::before {{ content: 'ğŸ¯'; }}
    .icon-risk::before {{ content: 'âš ï¸'; }}
    .icon-innovation::before {{ content: 'ğŸš€'; }}
    .icon-policy::before {{ content: 'ğŸ“‹'; }}
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <svg class="logo" viewBox="0 0 400 120" xmlns="http://www.w3.org/2000/svg">
        <defs>
          <linearGradient id="logoGradient" x1="0%" y1="0%" x2="100%" y2="100%">
            <stop offset="0%" style="stop-color:#8B5CF6;stop-opacity:1" />
            <stop offset="50%" style="stop-color:#3B82F6;stop-opacity:1" />
            <stop offset="100%" style="stop-color:#06B6D4;stop-opacity:1" />
          </linearGradient>
        </defs>
        <circle cx="40" cy="60" r="25" fill="url(#logoGradient)" opacity="0.8"/>
        <circle cx="25" cy="35" r="15" fill="url(#logoGradient)" opacity="0.9"/>
        <circle cx="55" cy="35" r="12" fill="url(#logoGradient)" opacity="0.7"/>
        <circle cx="35" cy="75" r="10" fill="url(#logoGradient)" opacity="0.6"/>
        <circle cx="60" cy="75" r="8" fill="url(#logoGradient)" opacity="0.8"/>
        <text x="90" y="45" font-family="Arial, sans-serif" font-size="24" font-weight="bold" fill="#3b82f6">ocean security</text>
        <text x="90" y="70" font-family="Arial, sans-serif" font-size="12" fill="#94a3b8">æµ·ä¹‹å®‰ï¼Œæ•°å­—å®‰å…¨ä¸“å®¶</text>
      </svg>
      <h1 class="title">æµ·ä¹‹å®‰ç½‘ç»œå®‰å…¨æ—¥æŠ¥</h1>
      <div class="subtitle">{current_time} Â· AIæ™ºèƒ½ç”Ÿæˆ</div>
    </div>
    
    <div class="content">
      <div class="summary-section">
        <h2 class="summary-title">ä»Šæ—¥æ‘˜è¦</h2>
        <div class="summary-content">{analysis_result.get('summary', 'ä»Šæ—¥æš‚æ— ç½‘ç»œå®‰å…¨æ–°é—»æ‘˜è¦')}</div>
      </div>
"""
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        sources = analysis_result.get('sources', [])
        regions = analysis_result.get('regions', [])
        
        html_template += f"""
      <div class="stats-section">
        <div class="stats-grid">
          <div class="stat-card">
            <div class="stat-number">{analysis_result.get('total_news', 0)}</div>
            <div class="stat-label">å…¨çƒå®‰å…¨æ–°é—»</div>
          </div>
          <div class="stat-card">
            <div class="stat-number">{len(sources)}</div>
            <div class="stat-label">æ–°é—»æ¥æº</div>
          </div>
          <div class="stat-card">
            <div class="stat-number">{len(regions)}</div>
            <div class="stat-label">è¦†ç›–åœ°åŒº</div>
          </div>
          <div class="stat-card">
            <div class="stat-number">{len(analysis_result.get('categories', {}))}</div>
            <div class="stat-label">å¨èƒåˆ†ç±»</div>
          </div>
        </div>
      </div>
"""
        
        # æ·»åŠ åˆ†ç±»æ–°é—»
        icon_map = {
            "é‡å¤§å®‰å…¨äº‹ä»¶": "icon-critical",
            "æ¼æ´ä¸å¨èƒæƒ…æŠ¥": "icon-risk", 
            "æŠ€æœ¯ä¸äº§ä¸šåŠ¨æ€": "icon-innovation",
            "æ”¿ç­–ä¸åˆè§„": "icon-policy"
        }
        
        for category, news_items in analysis_result.get('categories', {}).items():
            if news_items:
                icon_class = icon_map.get(category, "icon-focus")
                html_template += f"""
      <div class="category-section">
        <div class="category-header">
          <h2 class="category-title {icon_class}">{category}</h2>
        </div>
        <div class="category-news">
"""
                
                for item in news_items:
                    severity = item.get('severity', 'ä¸­å±')
                    severity_class = {
                        'é«˜å±': 'severity-high',
                        'ä¸­å±': 'severity-medium', 
                        'ä½å±': 'severity-low',
                        'ä¿¡æ¯': 'severity-info'
                    }.get(severity, 'severity-medium')
                    
                    html_template += f"""          <div class="news-item">
            <div class="news-header">
              <div class="news-title">{item['title']}</div>
              <div class="news-meta">
                <span class="news-source">{item.get('source', 'æœªçŸ¥æ¥æº')}</span>
                <span class="severity-badge {severity_class}">{severity}</span>
              </div>
            </div>
            <div class="news-analysis"><strong>AIæ·±åº¦åˆ†æï¼š</strong>{item['analysis']}</div>
          </div>
"""
                
                html_template += """        </div>
      </div>
"""
        
        # æ·»åŠ footer
        html_template += f"""    </div>
    
    <div class="footer">
      <p>Â© 2025 æµ·ä¹‹å®‰ï¼ˆä¸­å›½ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸ | åŸºäºæ™ºè°±GLM AIç”Ÿæˆ</p>
      <p>å…±åˆ†æ {analysis_result.get('total_news', 0)} æ¡å®‰å…¨æ–°é—» | å®˜ç½‘ï¼š<a href="https://www.oceansecurity.cn" style="color: #3b82f6;">www.oceansecurity.cn</a></p>
    </div>
  </div>
</body>
</html>"""
        
        return html_template
    
    def generate_daily_report(self, days_back: int = 1) -> str:
        """
        ç”Ÿæˆæ¯æ—¥å®‰å…¨å¿«æŠ¥
        
        Args:
            days_back: ç”Ÿæˆå‡ å¤©å‰çš„æŠ¥å‘Š
            
        Returns:
            ç”Ÿæˆçš„HTMLæ–‡ä»¶è·¯å¾„
        """
        try:
            # 1. æŠ“å–æ–°é—»
            news_list = self.fetch_security_news(days_back)
            
            if not news_list:
                logger.warning("æœªè·å–åˆ°ä»»ä½•æ–°é—»ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                return ""
            
            # 2. ä½¿ç”¨GLMç”Ÿæˆåˆ†æ
            logger.info("æ­£åœ¨ä½¿ç”¨GLMç”Ÿæˆæ–°é—»åˆ†æ...")
            analysis_result = self.generate_news_analysis(news_list)
            
            # 3. ç”ŸæˆHTMLæŠ¥å‘Š
            target_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y%m%d')
            html_content = self.generate_html_report(analysis_result, target_date)
            
            # 4. ä¿å­˜æ–‡ä»¶
            filename = f"news{target_date}.html"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"âœ… æˆåŠŸç”ŸæˆAIæ™ºèƒ½æ–°é—»å¿«æŠ¥: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""

def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥ï¼Œæˆ–è€…åœ¨è¿™é‡Œç›´æ¥è®¾ç½®
    api_key = os.getenv('GLM_API_KEY')
    
    if not api_key:
        print("âš ï¸  è¯·è®¾ç½®GLM_API_KEYç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­é…ç½®APIå¯†é’¥")
        print("è·å–APIå¯†é’¥ï¼šhttps://open.bigmodel.cn/")
        return
    
    generator = GLMNewsGenerator(api_key)
    
    # ç”Ÿæˆæ˜¨å¤©çš„æ–°é—»å¿«æŠ¥
    result = generator.generate_daily_report(days_back=1)
    
    if result:
        print(f"ğŸ‰ AIæ™ºèƒ½æ–°é—»å¿«æŠ¥ç”ŸæˆæˆåŠŸ: {result}")
    else:
        print("âŒ æ–°é—»å¿«æŠ¥ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()